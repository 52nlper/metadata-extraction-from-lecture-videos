34
000001355
Deep&54,Learning&54,for&54,NLP &54,.&0,Word&48,Vectors&48,and&48,Lexical&48,Semantics&48,.&0,Ed&19,.&0,OF&18,OXFORD&18,.&0
000114345
How&32,to&32,represent&32,words&32,.&0,Natural&27,language&27,text&27,sequences&27,of&27,discrete&27,symbols&27, e g &27,words  &27,.&0,Naive&25,representation &25,one&25,hot&25,vectors&25,in&25, very&25,large  &25,.&0,Classical&23,IR &23,document&23,and&23,query&23,vectors&23,are&23,superpositions&23,of&23,word&23,vectors &23,.&0,q &43,.&0,Similarly&28,for&28,word&28,classification&28,problems&28, e g &28,naive&28,bayes&28,topic&28,models  &28,.&0,Issues &27,sparse &27,orthogonal&27,representations &27,semantically&27,weak &27,.&0
000328386
How&32,to&32,represent&32,words&32,.&0,We&26,want&26,richer&26,representations&26,expressing&26,semantic&26,similarity &26,.&0,Distributional&24,semantics &24,.&0,”You&25,shall&25,know&25,a&25,word&25,by&25,the&25,company&25,it&25,keeps  &25,J R &25,Firth&25, 1957 &25,.&0,Idea &24,produce&24,dense&24,vector&24,representations&24,based&24,on&24,the&24,context use&24,of&24,words &24,.&0,Three&27,main&27,approaches &27,count-based &27,predictive &27,and&27,task-based &27,.&0
000453891
Count-based&33,methods&33,.&0,Define&23,a&23,basis&23,vocabulary&23,C&23,of&23,context&23,words &23,.&0,Define&22,a&22,word&22,window&22,size&22,w &22,.&0,Count&24,the&24,basis&24,vocabulary&24,words&24,occurring&24,w&24,words&24,to&24,the&24,left&24,or&24,right&24,of&24,each&24,.&0,instance&23,of&23,a&23,target&23,word&23,in&23,the&23,corpus &23,.&0,Form&23,a&23,vector&23,representation&23,of&23,the&23,target&23,word&23,based&23,on&23,these&23,counts &23,.&0
000592906
Count-based&33,methods&33,.&0,and&24,the&24,cute&24,kitten&24,purred&24,and&24,then&24,.&0,the&25,cute&25,furry&25,cat&25,purred&25,and&25,miaowed&25,.&0,that&24,the&24,small&24,kitten&24,miaowed&24,and&24,she&24,.&0,the&25,loud&25,furry&25,dog&25,ran&25,and&25,bit&25,.&0,Example&28,basis&28,vocabulary &28, bit &28,cute &28,furry &28,loud &28,miaowed &28,purred &28,ran &28,small  &28,.&0,kitten&26,context&26,words &26,purred &26,small &26,miaowed  &26,.&0,cat&25,context&25,words &25,furry &25,miaowed  &25,.&0,dog&26,context&26,words &26,furry &26,ran &26,bit  &26,.&0
000695444
Count—based&33,methods&33,.&0,and&24,the&24,cute&24,kitten&24,purred&24,and&24,then&24,.&0,the&24,cute&24,furry&24,cat&24,purred&24,and&24,miaowed&24,.&0,that&24,the&24,small&24,kitten&24,miaowed&24,and&24,she&24,.&0,the&24,loud&24,furry&24,dog&24,ran&24,and&24,bit&24,.&0,Example&28,basis&28,vocabulary &28,furry &28,loud &28,miaowed &28,purred &28,ran &28,small  &28,.&0,kitten&31,.&0,cat&28,.&0,dog&40,.&0
000711919
Count—based&32,methods&32,.&0,Use&24,inner&24,product&24,or&24,cosine&24,as&24,similarity&24,kernel &24,E g  &24,.&0,cat &37,cat &37,0 58&37,.&0,dog &37,dog &37,0 00&37,.&0,dog &37,dog &37,0 29&37,.&0,R&28,‘d&28,v —&28,.&0,Cosine&22,has&22,the&22,advantage&22,that&22,it's&22,a&22,norm—invariant&22,.&0
000767366
Count-based&33,methods&33,.&0,Not&23,all&23,features&23,are&23,equal &23,we&23,must&23,distinguish&23,counts&23,that&23,are&23,high&23,because&23,the&23,.&0,are&24,informative&24,from&24,those&24,that&24,are&24,just&24,independently&24,frequent&24,contexts &24,.&0,Many&26,normalisation&26,methods &26,TF-IDF &26,PMI &26,etc &26,.&0,Some&23,remove&23,the&23,need&23,for&23,norm-invariant&23,similarity&23,metrics &23,.&0,But   &24,perhaps&24,there&24,are&24,easier&24,ways&24,to&24,address&24,this&24,problem&24,of&24,count-based&24,.&0,methods&26, and&26,others &26,e g &26,choice&26,of&26,basis&26,context  &26,.&0
000904476
Neural&35,Embedding&35,Models&35,.&0,Learning&24,count&24,based&24,vectors&24,produces&24,an&24,embedding&24,matrix&24,in&24,.&0,furry&21,.&0,0&16,1&16,0&16,.&0,0&16,1&16,1&16,.&0,dog&17,1&17,0&17,1&17,.&0,Rows&21,are&21,word&21,vectors &21,so&21,we&21,can&21,retrieve&21,them&21,with&21,one&21,hot&21,vectors&21,in&21,.&0,cat&20,E&20,.&0,Symbols&27,unique&27,vectors &27,Representation&27,embedding&27,symbols&27,with&27,E &27,.&0
001014733
Neural&35,Embedding&35,Models&35,.&0, One &29,generic&29,idea&29,behind&29,embedding&29,learning &29,.&0,1 &23,Collect&23,instances&23,inst t &23,of&23,a&23,word&23,t&23,of&23,vocab&23,V &23,.&0,2 &25,For&25,each&25,instance &25,collect&25,its&25,context&25,words&25, e g &25,k-word&25,window  &25,.&0,3 &23,Define&23,some&23,score&23,function&23,8 &23,E &23,with&23,upper&23,bound&23,on&23,output &23,.&0,4 &22,Define&22,a&22,loss &22,.&0,L&29,.&0,5 &23,Estimate &23,.&0,arg&27,min&27,L&27,.&0,6 &23,Use&23,the&23,estimated&23,E&23,as&23,your&23,embedding&23,matrix &23,.&0
001089642
Neural&35,Embedding&35,Models&35,.&0,Scoring&26,function&26,matters &26,.&0,Easy&26,to&26,design&26,a&26,useless&26,scorer&26, e g &26,ignore&26,input &26,output&26,upper&26,bound  &26,.&0,Ideally &24,scorer &24,.&0,Embeds&26,with&26,E&26, obviously  &26,.&0,Produces&23,a&23,score&23,which&23,is&23,a&23,function&23,of&23,how&23,well&23,is&23,accounted&23,for&23,by&23,.&0,and or&22,vice&22,versa &22,.&0,Requires&24,the&24,word&24,to&24,account&24,for&24,the&24,context&24, or&24,the&24,reverse &24,more&24,than&24,.&0,another&24,word&24,in&24,the&24,same&24,place &24,.&0,Produces&22,a&22,loss&22,which&22,is&22,differentiable&22,w r t &22,9&22,and&22,E &22,.&0
001145615
Neural&35,Embedding&35,Models &35,C W&35, Co  obert&35,et&35,al &35,2011 &35,.&0,Embed&22,all&22,words&22,in&22,a&22,sentence&22,with&22,E &22,.&0,Shallow&24,convolution&24,over&24,embeddings &24,.&0,O&24,MLP&24,projects&24,output&24,of&24,convolution&24,to&24,a&24,.&0,scalar&21,score &21,.&0,Convolutions&25,and&25,MLP&25,are&25,parameterised&25,by&25,.&0,O&29,O&29,O&29,O&29,O&29,.&0,O&23,a&23,set&23,of&23,9 &23,.&0,O&29,.&0,Overall&22,network&22,models&22,a&22,function&22,over&22,.&0,O&29,O&29,O&29,O&29,0&29,.&0,sentences&19,3 &19,.&0
001244321
Neural&35,Embedding&35,Models &35,C W&35, Co  obert&35,et&35,al &35,2011 &35,.&0,OOOO&29,.&0,What&26,prevents&26,the&26,network&26,from&26,ignoring&26,.&0,input&27,and&27,outputting&27,high&27,scores &27,.&0,During&23,training &23,for&23,each&23,sentence&23,s&23,we&23,.&0,sample&24,a&24,distractor&24,sentence&24,z&24,by&24,randomly&24,.&0,corrupting&23,words&23,of&23,s &23,.&0,O&27,Minimise&27,hinge&27,loss &27,.&0,0&29,O&29,O&29,O&29,O&29,.&0,O&29,O&29,O&29,O&29,O&29,.&0,o&29,o&29,0&29,o&29,o&29,1&29,.&0
001563577
Neural&35,Embedding&35,Models &35,C W&35, Co  obert&35,et&35,al &35,2011 &35,.&0,OOOO&146,OOOO&146,OOOO&146,.&0,OOOO&29,.&0,convolution&18,.&0,Interpretation &28,representations&28,carry&28,.&0,information&26,about&26,what&26,neighbouring&26,.&0,representations&26,should&26,look&26,like &26,.&0,A&25,lot&25,like&25,the&25,distributional&25,hypothesis &25,.&0,A&24,sensible&24,model&24,but &24,.&0,Fairly&25,deep &25,so&25,not&25,cheap&25,to&25,train &25,.&0,Convolutions&25,capture&25,very&25,local&25,information &25,.&0
001642620
Neural&35,Embedding&35,Models &35,CBoW&35, Mikolov&35,et&35,al &35,2013 &35,.&0,Embed&23,context&23,words &23,Add&23,them &23,.&0,O&28,.&0,Project&26,back&26,to&26,vocabulary&26,Softmax &26,.&0,O&26,O&26,O&26,O&26,E&26,.&0,Minimize&27,Negative&27,Log&27,Likelihood &27,.&0,O&29,O&29,O&29,O&29,.&0,O&30,.&0,wn-2&27,wn-1&27,wn 1&27,wn 2&27,.&0
001857114
Neural&35,Embedding&35,Models &35,CBoW&35, Mikolov&35,et&35,al &35,2013 &35,.&0,All&24,linear &24,so&24,very&24,Basically&24,a&24,cheap&24,way&24,.&0,O&25,O&25,O&25,of&25,applying&25,one&25,matrix&25,to&25,all&25,inputs &25,.&0,Historically &28,negative&28,sampling&28,used&28,instead&28,.&0,Q&27,Q&27,Q&27,of&27,expensive&27,softmax &27,.&0,NLL&23,minimisation&23,is&23,more&23,stable&23,and&23,is&23,fast&23,.&0,O&30,O&30,.&0,enough&31,today &31,.&0,0&29,O&29,O&29,O&29,.&0,O&27,O&27,O&27,O&27,Variants &27,position&27,specific&27,matrix&27,per&27,input&27,.&0,O&28,O&28,O&28,O&28, Ling&28,et&28,al &28,2015  &28,.&0,wn-2&27,wn-1&27,wn 1&27,wn 2&27,.&0
001957934
Neural&37,Embedding&37,Models &37,Skip-gram&37, Mikolov&37,et&37,al &37,2013 &37,.&0,Target&26,word&26,predicts&26,context&26,words &26,.&0,i  n-2 n 2 - n &21,.&0,O&41,O&41,O&41,O&41,.&0,Embed&25,target&25,word &25,.&0,Transform&27,Project&27,into&27,vocabulary &27,Softmax &27,.&0,T&24,so&24,E&24,.&0,Learn&23,to&23,estimate&23,likelihood&23,of&23,context&23,words &23,.&0,w&26,—log&26,.&0,n&18,.&0,E&15,.&0
002029156
Neural&37,Embedding&37,Models &37,Skip-gram&37, Mikolov&37,et&37,al &37,2013 &37,.&0,Fast &25,One&25,embedding&25,versus&25, C &25,embeddings &25,.&0,i  n-2 n 2 &21, n &21,.&0,OOOO&42,.&0,Transform&25,Similar&25,variants&25,to&25,CBoW&25,possible &25,position&25,.&0,specific&31,projections &31,.&0,Softmax&26,.&0,O&29,O&29,O&29,Trade&29,off&29,between&29,efficiency&29,and&29,more&29,structured&29,.&0,notion&22,of&22,context &22,.&0,Just&25,read&25,off&25,probabilities&25,from&25,softmax &25,.&0
002169860
Comparison&34,with&34,Count—Based&34,Models&34,.&0,Count&25,based&25,and&25,objective-based&25,models &25,same&25,general&25,idea &25,.&0,Word2Vec&24,PMI&24,matrix&24,factorization&24,of&24,count&24,based&24,models&24,.&0, Levy&30,and&30,Goldberg &30,2014 &30,.&0,Count&25,based&25,and&25,most&25,neural&25,models&25,have&25,equivalent&25,performance&25,when&25,.&0,properly&28,hyperoptimized&28, Levy&28,et&28,al &28,2015 &28,.&0
002353906
Specific&36,Benefits&36,of&36,Neural&36,Approaches&36,.&0,Easy&27,to&27,learn &27,especially&27,with&27,good&27,linear&27,algebra&27,libraries &27,.&0,Highly&28,parallel&28,problem &28,minibatching &28,GPUs &28,distributed&28,models &28,.&0,Can&26,predict&26,other&26,discrete&26,aspects&26,of&26,context&26, dependencies &26,POS&26,tags &26,etc  &26,Can&26,.&0,estimate&26,these&26,probabilities&26,with&26,counts &26,but&26,sparsity&26,quickly&26,becomes&26,a&26,problem &26,.&0,Can&24,predict condition&24,on&24,continuous&24,contexts &24,e g &24,images &24,.&0
002427763
Evaluating&38,Word&38,Representations&38,.&0,Intrinsic&24,Evaluation &24,.&0,WordSim-353&27, Finkelstein&27,et&27,al &27,2003 &27,.&0,SimLex-999&25, Hill&25,et&25,al &25,2016 &25,but&25,has&25,been&25,around&25,since&25,2014 &25,.&0,Word&27,analogy&27,task&27, Mikolov&27,et&27,2013 &27,.&0,Embedding&29,visualisation&29, nearest&29,neighbours &29,T-SNE&29,projection &29,.&0,vec  king  &20,vec “woman  &20,.&0,n&9,.&0
002765870
Evaluating&38,Word&38,Representations&38,.&0,Extrinsic&24,Evaluation &24,.&0,Simply &27,do&27,your&27,embeddings&27,improve&27,performance&27,on&27,other&27,task s  &27,.&0,More&22,on&22,this&22,later   &22,.&0
002799495
Evaluating&38,Word&38,Representations&38,.&0,Intrinsic&24,Evaluation &24,.&0,WordSim-353&27, Finkelstein&27,et&27,al &27,2003 &27,.&0,SimLex-999&25, Hill&25,et&25,al &25,2016 &25,but&25,has&25,been&25,around&25,since&25,2014 &25,.&0,Word&27,analogy&27,task&27, Mikolov&27,et&27,2013 &27,.&0,Embedding&29,visualisation&29, nearest&29,neighbours &29,T-SNE&29,projection &29,.&0,vec  king  &20,vec “woman  &20,.&0,l&6,.&0
002803976
Task-based&38,Embedding&38,Learning&38,.&0,Just&24,saw&24,methods&24,for&24,learning&24,Ethrough&24,minimising&24,a&24,.&0,One&23,use&23,for&23,E&23,is&23,to&23,get&23,input&23,features&23,to&23,a&23,neural&23,network&23,from&23,words &23,.&0,Neural&25,network&25,parameters&25,are&25,updated&25,using&25,gradients&25,on&25,loss&25,L x &25,y &25,9  &25,.&0,If&24,E&24,8&24,then&24,this&24,update&24,can&24,modify&24,E&24, if&24,we&24,let&24,it  &24,.&0,y &32,.&0
002924564
Task-based&38,Embedding&38,Learning&38,.&0,We&25,can&25,therefore&25,directly&25,train&25,embeddings&25,jointly&25,with&25,the&25,parameters&25,of&25,the&25,.&0,network&23,which&23,uses&23,them &23,.&0,General&24,intuition &24,learn&24,to&24,cIassify predict generate&24,based&24,on&24,features &24,but&24,also&24,.&0,the&24,features&24,themselves &24,.&0,Embeddings&24,matrix&24,can&24,be&24,learned&24,from&24,scratch &24,or&24,initialised&24,with&24,pre-learned&24,.&0,embeddings&31, fine-tuning  &31,.&0
002988333
Task-based&32,Features &32,BoW&32,Classifiers&32,.&0,We&23,want&23,to&23,classify&23,sentences documents&23,based&23,on&23,a&23,variable&23,number&23,of&23,word&23,.&0,representations &29,.&0,Simplest&27,option &27,bag&27,of&27,vectors &27,.&0,P C D &32,.&0,Projection&27,into&27,logits&27, input&27,to&27,softmax &27,can&27,be&27,arbitrarily&27,complex &27,E g  &27,.&0,P C D &31,.&0
003102010
Task-based&32,Features &32,BoW&32,Classifiers&32,.&0,Simple&26,to&26,implement&26,and&26,train &26,.&0,Example&28,tasks &28,.&0,Sentiment&28,analysis&28, e g &28,tweets &28,movie&28,reviews  &28,.&0,Document&27,classification&27, e g &27,20&27,Newsgroups &27,.&0,Author&25,identification &25,etc   &25,.&0,We&25,learn&25,task-specific&25,features &25,eg &25,notion&25,of&25,positive negative&25,words&25,in&25,.&0,sentiment&27,analysis &27,.&0,We&24,can&24,think&24,of&24,word&24,meaning&24,as&24,being&24,grounded&24,in&24,the&24,task &24,.&0
003142808
Task-based&32,Features &32,BOW&32,Classifiers&32,.&0,But &25,no&25,notion&25,of&25,words&25,in&25,context&25, ambiguity &25,polysemy  &25,.&0,Cannot&25,capture&25,saliency&25,of&25,individual&25,words &25,Everything&25,contributes&25,to&25,the&25,.&0,decision &21,so&21,more&21,words&21,more&21,noise &21,.&0,Grounding&26,in&26,classification&26,tasks&26,can&26,yield&26,quite&26,shallow&26,semantics &26,E g  &26,.&0,There&24,is&24,more&24,to&24,the&24,word&24, good &24,than&24,the&24,sentiment&24,expressed &24,.&0,There&24,is&24,more&24,to&24, CPU &24,than&24,the&24,fact&24,that&24,it&24,predicts&24,the&24,topic&24, computer  &24,.&0
003227623
Task-based&34,Features &34,Bilingual&34,Features&34,.&0,Simple&27,objectives&27,can&27,yield&27,better&27,grounding&27,for&27,word&27,.&0,Example &25,recognising&25,cross-lingual&25,sentence&25,alignment&25,based&25,on&25,word&25,vectors&25,.&0, Hermann&25,and&25,Blunsom&25,2014  &25,Consider&25,a&25,dataset&25,of&25,English&25,sentences&25,and&25,their&25,.&0,German&26,translations &26,.&0,We&25,want&25,to&25,produce&25,representations&25,and&25,of&25,the&25,English&25,and&25,German&25,sentence&25,.&0,such&24,the&24,similarity&24,between&24,the&24,vectors&24,is&24,maximised &24,.&0,We&24,use&24,this&24,objective&24,to&24,train&24,embedding&24,matrices&24,and&24,for&24,English&24,and&24,.&0,German&24,words &24,.&0
003299593
Task-based&33,Features &33,Bilingual&33,Features&33,.&0,Sentence&25,representations&25,are&25,produced&25,with&25,a&25,simple&25,composition&25,You&25,.&0,could&24,do&24,bag&24,of&24,words &24,or&24,some&24,aspect&24,of&24,word&24,order &24,e g &24,.&0,An&23,obvious&23,loss&23,would&23,be &23,.&0,2&27,L&27,.&0,Obvious&25,degenerate&25,solution&25,to&25,this&25,objective&25,is &25,.&0
003446513
Task-based&34,Features &34,Bilingual&34,Features&34,.&0,So&23,we&23,avoid&23,the&23,degenerate&23,case&23,with&23,a&23,noise-contrastive&23,margin-based&23,loss &23,.&0,L&28,IDI &28,.&0,Sample&24,a&24,random&24,German&24,sentence&24,per&24,data&24,point&24,as&24,noise &24,Impose&24,the&24,.&0,constraint&24,that&24,the&24,margin&24,of&24,similarity&24,between&24,a&24,paired&24,pair&24,of&24,sentences&24,and&24,an&24,.&0,unpaired&25,pair&25,of&25,sentences&25,be&25,at&25,least&25,m&25, some&25,hyperparameter  &25,.&0,Intuition &26,aligned&26,sentences&26,share&26,high-level&26,meaning &26,so&26,embeddings&26,should&26,.&0,reflect&25,the&25,high-level&25,meaning&25,in&25,order&25,to&25,minimise&25,loss &25,.&0
003548853
Task-based&32,Features &32,Other&32,Models&32,.&0,These&23,models&23,are&23,all&23,very&23,simple&23, this&23,is&23,not&23,a&23,bad&23,There&23,are&23,many&23,other&23,.&0,options &29,.&0,How&24,do&24,we&24,capture&24,the&24,relation&24,between&24,words &24,Disambiguation &24,The&24,context&24,.&0,they&23,occur&23,in &23,How&23,do&23,we&23,use&23,these&23,embeddings&23,effectively &23,.&0,This&24,is&24,a&24,recurring&24,topic&24,for&24,the&24,rest&24,of&24,this&24,course &24,but&24,general&24,idea&24,is &24,.&0
003608226
Task-based&34,Features &34,Interpretation&34,.&0,Task-based&25,embeddings&25,capture&25,information&25,salient&25,to&25,the&25,task &25,Again &25,no&25,.&0,guarantee&26,this&26,will&26,capture&26, general &26,meaning&26,beyond&26,features&26,useful&26,for&26,the&26,task &26,.&0,This&22,can&22,be&22,overcome&22,by&22,using&22,a&22,multi-task&22,objective&22,but&22,this&22,comes&22,with&22,its&22,own&22,.&0,difficulties &25,.&0,Alternatively &26,embeddings&26,can&26,be&26,pretrained&26,and&26,fixed &26,relying&26,on&26,task-specific&26,.&0,projections&27,into&27,the&27,network &27,but&27,is&27,the&27,pretraining&27,objective&27,general&27,enough &27,.&0,E g &25,It&25,might&25,project&25, cat &25,and&25, kitten &25,into&25,a&25,similar&25,part&25,of&25,the&25,embedding&25,space &25,.&0,but&25,a&25,task&25,might&25,need&25,to&25,radically&25,differentiate&25,these&25,concepts &25,.&0
003662828
Final&33,Words&33,.&0,Learning&25,and&25,re-using&25,word&25,vectors&25,is&25,a&25,form&25,of&25,transfer&25,learning &25,It&25,is&25,particularly&25,.&0,useful&25,if&25,you&25,have&25,little&25,task-specific&25,training&25,data &25,or&25,poor&25,coverage&25,of&25,the&25,.&0,vocabulary&25, in&25,which&25,case&25,you&25,might&25,not&25,want&25,to&25,fine-tune&25,embeddings  &25,.&0,Generally&28,speaking &28,if&28,you&28,have&28,enough&28,training&28,data&28, and&28,coverage &28,.&0,you&25,will&25,benefit&25,from&25,training&25,embeddings&25,on&25,the&25,task &25,at&25,the&25,cost&25,of&25,reusability &25,.&0,Take&24,home&24,message&24,of&24,this&24,lecture &24,.&0,Inputs&23,to&23,neural&23,networks&23,over&23,text&23,are&23,embeddings &23,.&0,We&23,can&23,train&23,them&23,separately &23,within&23,a&23,particular&23,task &23,or&23,both &23,.&0
